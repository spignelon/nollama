# ============================================================================
# NOLLAMA CONFIGURATION
# ============================================================================
# This file contains all configuration options for nollama.
# Copy this file to .env and fill in your API keys and preferences.
# If .env doesn't exist, nollama will fall back to ~/.nollama for API keys.
# ============================================================================

# ----------------------------------------------------------------------------
# GENERAL SETTINGS
# ----------------------------------------------------------------------------

# Default provider to use (if not set, user will be prompted)
# Options: gemini, vertex_ai, groq, ollama, anthropic, deepseek, openai, openrouter
# DEFAULT_PROVIDER=gemini

# Default model to use (if not set, user will be prompted)
# DEFAULT_MODEL=gemini-2.5-flash-preview-05-20

# Enable streaming by default (true/false)
# STREAM=true

# ----------------------------------------------------------------------------
# API KEYS - Google Gemini (Google AI Studio)
# ----------------------------------------------------------------------------
# Get your key from: https://makersuite.google.com/app/apikey
# GEMINI_API_KEY=your_gemini_api_key_here

# ----------------------------------------------------------------------------
# API KEYS - Google Vertex AI
# ----------------------------------------------------------------------------
# For Vertex AI, you need to set up Google Cloud authentication
# VERTEX_PROJECT=your_gcp_project_id
# VERTEX_LOCATION=us-central1
# GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account-key.json

# ----------------------------------------------------------------------------
# API KEYS - Groq
# ----------------------------------------------------------------------------
# Get your key from: https://console.groq.com/keys
# GROQ_API_KEY=your_groq_api_key_here

# ----------------------------------------------------------------------------
# API KEYS - Ollama
# ----------------------------------------------------------------------------
# Ollama runs locally, just specify the base URL
# OLLAMA_API_BASE=http://localhost:11434

# ----------------------------------------------------------------------------
# API KEYS - Anthropic (Claude)
# ----------------------------------------------------------------------------
# Get your key from: https://console.anthropic.com/
# ANTHROPIC_API_KEY=your_anthropic_api_key_here

# ----------------------------------------------------------------------------
# API KEYS - DeepSeek
# ----------------------------------------------------------------------------
# Get your key from: https://platform.deepseek.com/
# DEEPSEEK_API_KEY=your_deepseek_api_key_here

# ----------------------------------------------------------------------------
# API KEYS - OpenAI
# ----------------------------------------------------------------------------
# Get your key from: https://platform.openai.com/api-keys
# OPENAI_API_KEY=your_openai_api_key_here

# ----------------------------------------------------------------------------
# API KEYS - OpenRouter
# ----------------------------------------------------------------------------
# Get your key from: https://openrouter.ai/keys
# OPENROUTER_API_KEY=your_openrouter_api_key_here
# OPENROUTER_API_BASE=https://openrouter.ai/api/v1
# OR_SITE_URL=https://yoursite.com  # Optional: for OpenRouter rankings
# OR_APP_NAME=nollama  # Optional: for OpenRouter rankings

# ----------------------------------------------------------------------------
# ADVANCED SETTINGS
# ----------------------------------------------------------------------------

# Maximum tokens for completion
# MAX_TOKENS=4096

# Temperature (0.0 to 2.0)
# TEMPERATURE=0.7

# Top-p sampling
# TOP_P=1.0

# Enable debug mode (shows raw API calls)
# DEBUG=false

# Custom model configuration (JSON format)
# Useful for adding custom models not in the default list
# CUSTOM_MODELS={"provider/model-name": "Display Name"}
